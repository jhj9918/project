{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXwU_JZQXqBA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR2-FdMwZKx9"
      },
      "source": [
        "df = pd.read_excel('/content/df.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9DjLdWSbc9n"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "                                                         \n",
        "train_data, test_data = train_test_split(df, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0YI3pDMrBgV"
      },
      "source": [
        "train_data.drop_duplicates(subset=['발화'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohFo1BsKrIWQ",
        "outputId": "ef1571b5-d127-4e06-a954-5543dc4848d7"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n",
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npLx0ogvrQxA",
        "outputId": "630beeb1-2266-437f-c27c-2c917f864009"
      },
      "source": [
        "print(train_data.isnull().values.any()) # Null 값 확인\n",
        "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "전처리 후 테스트용 샘플의 개수 : 750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "6BHUDNAP40Hx",
        "outputId": "76a03779-fee0-4d7d-b119-6d10d2c71ea3"
      },
      "source": [
        "train_data['발화'] = train_data['발화'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 한글과 공백을 제외하고 모두 제거\n",
        "\n",
        "train_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2ba7457-32ca-4ea3-96e1-985e662e61ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>발화</th>\n",
              "      <th>코드</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>안내사항 설명하는방법을 개선했으면 함</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>친절한 상담에 감사드립니다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>연결하는 대기시간 너무길다</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>카드는 상담하면 기분이 나뻐집니다 ㅋ삼성은 좋아요</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>통화대기시간이 매우길다</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2ba7457-32ca-4ea3-96e1-985e662e61ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2ba7457-32ca-4ea3-96e1-985e662e61ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2ba7457-32ca-4ea3-96e1-985e662e61ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              발화  코드\n",
              "253         안내사항 설명하는방법을 개선했으면 함   4\n",
              "667               친절한 상담에 감사드립니다   1\n",
              "85                연결하는 대기시간 너무길다   5\n",
              "969  카드는 상담하면 기분이 나뻐집니다 ㅋ삼성은 좋아요  23\n",
              "75                  통화대기시간이 매우길다   5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ttYMSuR6G79",
        "outputId": "02e56592-9483-4bae-ce5d-fbdcd3881050"
      },
      "source": [
        "test_data.drop_duplicates(subset = ['발화'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
        "test_data['발화'] = test_data['발화'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['발화'] = test_data['발화'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
        "test_data['발화'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후 테스트용 샘플의 개수 : 250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ6UkPo-6Z0X"
      },
      "source": [
        "# 토큰화\n",
        "\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] # 불용어 사전"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQJAU5o77R40",
        "outputId": "34e1f56f-fbe8-4431-8071-5d443c050f02"
      },
      "source": [
        "# 토근화 실행\n",
        "!python -m pip install --upgrade konlpy\n",
        "import konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1vcqk8u8CIy"
      },
      "source": [
        " # 형태소 분석 + stem = True 정규화\n",
        "\n",
        "from konlpy.tag import Okt  \n",
        "okt=Okt()\n",
        "\n",
        "X_train = []\n",
        "for sentence in train_data['발화']:\n",
        "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_train.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHroeBwt8LY7",
        "outputId": "b9429759-357e-4b00-dca8-7dad169260c1"
      },
      "source": [
        "X_train[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['안내', '사항', '설명', '방법', '을', '개선', '함'],\n",
              " ['친절하다', '상담', '감사', '드리다'],\n",
              " ['연결하다', '대기', '시간', '너무', '길다'],\n",
              " ['카드', '상담', '기분', '나쁘다', '지다', 'ㅋ', '삼성', '좋다'],\n",
              " ['통화', '대기', '시간', '매우', '길다'],\n",
              " ['매우', '친절하다', '감사하다'],\n",
              " ['상담', '친절하다', '받다', '감사하다'],\n",
              " ['연', '회비', '너무', '부담', '되다'],\n",
              " ['삼', '성', '전자', '부장', '님', '친절하다', '설명', '해주다', '감사', '드리다', '김치냉장고', '구입'],\n",
              " ['골드', '회원', '전용전', '화', '상담', '원', '비치', '되어다', '으', '면', '좋다']]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lwWpYrv9QmR"
      },
      "source": [
        "# 테스트 데이터\n",
        "X_test = []\n",
        "for sentence in test_data['발화']:\n",
        "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_test.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIL-mfg09Xpu"
      },
      "source": [
        "# 정수 인코딩\n",
        "\n",
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ3-oJ-u-YpV",
        "outputId": "46d614b1-2b42-4518-f830-5048c9a597a1"
      },
      "source": [
        "print(X_train[:3])\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[38, 131, 39, 111, 7, 208, 102], [2, 1, 15, 19], [115, 21, 10, 4, 33]]\n",
            "{'상담': 1, '친절하다': 2, '감사하다': 3, '너무': 4, '해주다': 5, '연결': 6, '을': 7, '좋다': 8, '원': 9, '시간': 10, '통화': 11, '되다': 12, '카드': 13, '화면': 14, '감사': 15, '직원': 16, '친절': 17, '있다': 18, '드리다': 19, '고객': 20, '대기': 21, '상담사': 22, '없다': 23, '불편하다': 24, '전화': 25, '받다': 26, '처리': 27, '로': 28, '연': 29, '되어다': 30, '터치': 31, '정확하다': 32, '길다': 33, '회비': 34, '않다': 35, '때': 36, '보이다': 37, '안내': 38, '설명': 39, '다': 40, '다른': 41, '빠르다': 42, '삼성': 43, '내용': 44, '까지': 45, '에서': 46, '답변': 47, '같다': 48, '많이': 49, '분': 50, '바로': 51, '응대': 52, '대': 53, '기': 54, '모르다': 55, '적': 56, '시': 57, '요': 58, '질문': 59, '더': 60, '기분': 61, '성': 62, '면': 63, '어렵다': 64, '회사': 65, '사': 66, '서비스': 67, '매우': 68, '아니다': 69, '삼': 70, '비싸다': 71, '기다': 72, '과의': 73, '하': 74, '하고': 75, '음성': 76, '무': 77, '이자': 78, '안되다': 79, '자다': 80, '보다': 81, '것': 82, '생각': 83, '번': 84, '짧다': 85, '할부': 86, '기다리다': 87, '만': 88, '문의': 89, '말투': 90, '넘다': 91, '앱': 92, '선택': 93, '빨리': 94, '많다': 95, '알다': 96, '좀더': 97, '이다': 98, '신속하다': 99, '주다': 100, '인': 101, '함': 102, '안': 103, '필요하다': 104, '힘들다': 105, '타': 106, '내': 107, '일': 108, '메뉴': 109, '디지털': 110, '방법': 111, '주말': 112, '혜택': 113, '사용': 114, '연결하다': 115, '님': 116, '없이': 117, '고맙다': 118, '니': 119, '편하다': 120, '복잡하다': 121, '입장': 122, '답답하다': 123, '아주': 124, '넘어가다': 125, '대해': 126, '원하다': 127, '가다': 128, '못': 129, '느끼다': 130, '사항': 131, '골드': 132, '중': 133, '느낌': 134, '교육': 135, '후': 136, '조금': 137, '이나': 138, '쉬다': 139, '에게': 140, '불만': 141, '대한': 142, '누르다': 143, '처음': 144, '수': 145, '부분': 146, '전화하다': 147, '말': 148, '감동': 149, '문자': 150, '오늘': 151, '해결': 152, '응': 153, '정말': 154, '제': 155, '쓰다': 156, '들다': 157, '이기다': 158, '나오다': 159, '나쁘다': 160, '회원': 161, '항상': 162, '대출': 163, '에도': 164, '부탁': 165, '만족': 166, '궁금하다': 167, '답': 168, '업무': 169, '방식': 170, '직접': 171, '바라다': 172, '듣다': 173, '불편': 174, '만들다': 175, '포인트': 176, '번호': 177, '신속': 178, '나': 179, '스럽다': 180, '보험': 181, '걸리다': 182, '먼저': 183, '상담시': 184, '인데': 185, '오다': 186, '짜증': 187, '신한카드': 188, '용이': 189, '부탁드리다': 190, '경우': 191, '본인': 192, '톡': 193, '가능하다': 194, '줄다': 195, '전': 196, 'ㅡ': 197, '지': 198, '라고': 199, '텔레콤': 200, '이해': 201, '에는': 202, '문제': 203, '멘트': 204, '형식': 205, '롯데': 206, '제대로': 207, '개선': 208, '슴': 209, '읍': 210, '상환': 211, '돼다': 212, '그렇다': 213, '식': 214, '때문': 215, '크다': 216, '힘': 217, '상': 218, '주시': 219, '말씀': 220, '끝': 221, '이야기': 222, '적다': 223, '분들': 224, '해당': 225, '차다': 226, '어': 227, '등': 228, '엔': 229, '도움': 230, '보고': 231, '위해': 232, '임': 233, '공부': 234, '별로': 235, '스마트폰': 236, '이용': 237, '편리하다': 238, '확인': 239, '상냥하다': 240, '사람': 241, '넘기다': 242, '해': 243, '배려': 244, '자세하다': 245, '계속': 246, '곳': 247, '가끔': 248, '그': 249, '최선': 250, '마음': 251, '파악': 252, '어려움': 253, '센터': 254, '광고': 255, '같이': 256, '부족하다': 257, '야': 258, '알': 259, '발음': 260, '디지털로': 261, '찾다': 262, '힘드다': 263, '더욱': 264, '성의': 265, '만족하다': 266, '너': 267, '빨': 268, '부담': 269, '으': 270, '네': 271, 'ㅇ': 272, '햇': 273, '늘다': 274, '지만': 275, '미리': 276, '대화': 277, '게': 278, '소비자': 279, '한도': 280, '대응': 281, '채팅': 282, '통한': 283, '해보다': 284, '주심': 285, '해주': 286, '전환': 287, '통해': 288, '서': 289, '라서': 290, '국민카드': 291, '다시': 292, '권유': 293, '콜센터': 294, '부족': 295, '영혼': 296, '이고': 297, '찾기': 298, '줄': 299, '목소리': 300, '싫다': 301, '해지': 302, '사의': 303, '적립': 304, '보이': 305, '수고': 306, '역시': 307, '듯': 308, '얘기': 309, '캐피탈': 310, '인지': 311, '에서는': 312, '입력': 313, '만족스럽다': 314, '아': 315, '말다': 316, '음': 317, '제공': 318, '말고': 319, '불친절하다': 320, '쉽다': 321, '잘해주다': 322, '비': 323, '납부': 324, '버튼': 325, '대답': 326, '통신사': 327, '자주': 328, '한번': 329, '오래': 330, '연락': 331, '도와주다': 332, '그냥': 333, '저': 334, '원님': 335, '적극': 336, '필요': 337, '하루': 338, '담당': 339, '시스템': 340, '보내다': 341, '시키다': 342, '대시': 343, 'ㅠㅠ': 344, '상품': 345, '전자': 346, '구입': 347, '지금껏': 348, '속': 349, '제일': 350, '에선': 351, '간': 352, '신한': 353, '주': 354, '용하다': 355, '이동': 356, '사다': 357, '운영': 358, '코로나': 359, '톤': 360, '야하다': 361, '잇다': 362, '느리다': 363, '어리다': 364, '간단하다': 365, '편': 366, '걸': 367, '지연': 368, '맞다': 369, '내다': 370, 'ㅜㅜ': 371, '번거롭다': 372, '태도': 373, '여': 374, '그대로': 375, '싶다': 376, '그게': 377, '핸드폰': 378, '살다': 379, '자동': 380, '곧바로': 381, '다소': 382, '분실': 383, '처럼': 384, '정도': 385, '경험': 386, '관련': 387, '마케팅': 388, '친철': 389, '투': 390, '박하다': 391, '둘': 392, '줌': 393, '관리': 394, '비다': 395, '뭔': 396, '신한은행': 397, '추가': 398, '한적': 399, '기억': 400, 'ㅁ': 401, '끊다': 402, '귀찮다': 403, '덥다': 404, '물어보다': 405, '자리': 406, '고마움': 407, '느껴지다': 408, '년': 409, '사실': 410, '남기다': 411, '데': 412, '이라': 413, '따르다': 414, '놀라다': 415, '방금': 416, '면제': 417, '최고': 418, '그것': 419, '메일': 420, '비밀번호': 421, '자꾸': 422, '두': 423, '씩': 424, '메인': 425, '가장': 426, '카톡': 427, '기존': 428, '끄다': 429, '창': 430, '불필요하다': 431, '라': 432, '급하다': 433, '기대하다': 434, '구성': 435, '째': 436, '해주시': 437, '나중': 438, '여러': 439, '실질': 440, '부담스럽다': 441, '그저': 442, '책임지다': 443, '나다': 444, '잘알다': 445, '나이': 446, '엄청': 447, '건강': 448, '불': 449, '늘': 450, '맘대로': 451, '공감': 452, '보기': 453, '실시간': 454, '근무': 455, '과정': 456, '디지탈': 457, '사보다': 458, '읍니': 459, '상당하다': 460, '지체': 461, '차분하다': 462, '상당': 463, '보통': 464, '고': 465, '무오': 466, '래': 467, '홈페이지': 468, '전용': 469, '조': 470, '응답': 471, '정확': 472, '이상': 473, '시도': 474, '보다는': 475, '신청': 476, '오랜': 477, '확실하다': 478, '전체': 479, '인원': 480, '께': 481, '세': 482, '길음': 483, '부족함': 484, '끝나다': 485, '늦다': 486, '진행': 487, '지다': 488, 'ㅋ': 489, '부장': 490, '김치냉장고': 491, '전용전': 492, '화': 493, '비치': 494, '메우다': 495, '기능': 496, '최저': 497, '도감': 498, '몐트': 499, '론': 500, '훨씬': 501, '로이': 502, '괜히': 503, '결과': 504, '동시': 505, '잘쓰다': 506, '사랑': 507, '배송': 508, '불친철': 509, '사도': 510, '마찬가지': 511, '절차': 512, '을사': 513, '분분': 514, '체크': 515, '탤레콤': 516, '갸': 517, '막상막하': 518, '엡니': 519, '려': 520, '하나은행': 521, '중소': 522, '복': 523, '연겔': 524, '마': 525, '우': 526, '유발': 527, '예상': 528, '가기': 529, '짤': 530, '따지다': 531, '월': 532, '정액': 533, '추천': 534, '줳으면좋겧': 535, '초반': 536, '애기': 537, '예컨대': 538, '의상': 539, '담': 540, '체험': 541, '점': 542, '배우다': 543, '실행': 544, '어떤': 545, '담하다': 546, '해달라다': 547, '초이': 548, '언행': 549, '죠': 550, '부터': 551, '접근': 552, '경청': 553, '셧': 554, '서툴다': 555, '헤맺음': 556, '단축키': 557, '헷갈리다': 558, '글씨': 559, '작다': 560, '간결하다': 561, '번항': 562, '야간': 563, '신고': 564, '책임감': 565, '짐': 566, '누구': 567, '이렇게': 568, '홈피': 569, '보지': 570, '누가': 571, '복지': 572, '싱': 573, '전문성': 574, '상세': 575, '불쾌하다': 576, '무의미': 577, '오': 578, '전담': 579, '사건': 580, '결': 581, '역년': 582, '에서도': 583, '등등': 584, '확대': 585, '상투': 586, '반면': 587, '보앱': 588, '멀다': 589, '통신': 590, '료': 591, '및': 592, '심다': 593, '보안': 594, '모니터링': 595, '보이스피싱': 596, '당한': 597, '심하다': 598, '전문직': 599, '식이': 600, '선입견': 601, '택': 602, '존댓말': 603, '반': 604, '굉장하다': 605, '저러다': 606, '알수없음': 607, '볼': 608, '모바일': 609, '계좌': 610, '계설': 611, '성심': 612, '성의껏': 613, '남다': 614, '사례': 615, '해하': 616, '반복': 617, '동문서답': 618, '가타': 619, '인사': 620, '뚝': 621, '버리다': 622, '뿐': 623, '이렇다': 624, '당황': 625, '끌다': 626, '거나': 627, '통화시': 628, '거치다': 629, '단계': 630, '회피': 631, '판매점': 632, '사원': 633, '하니': 634, '참말': 635, '메세지': 636, '구': 637, '분할수': 638, '문의사항': 639, '에게는': 640, '홈쇼핑': 641, '법': 642, '일도': 643, '비우다': 644, '모습': 645, '엄청나다': 646, '대하': 647, '하이': 648, '계시다': 649, '말씀드리다': 650, '빨르다': 651, '엇음': 652, '우체국': 653, '요구사항': 654, '최초': 655, '계': 656, '제휴': 657, '궁': 658, '금사항': 659, '자상하다': 660, '차': 661, '용다': 662, '알아보다': 663, '르노': 664, '합병': 665, '근저당': 666, '설정': 667, '요건': 668, '소멸': 669, '왜': 670, '본사': 671, '몫': 672, '놓다': 673, '라는': 674, '얼마나': 675, '판매': 676, '종료': 677, '난해하다': 678, '도하': 679, '등급': 680, '챗봇': 681, '쓸데없이': 682, '이전': 683, '분운': 684, '제발': 685, '놉': 686, '걸다': 687, '소비': 688, '결부': 689, '플래티늄': 690, '데스크': 691, '이유': 692, '이며': 693, '생년': 694, '월일': 695, '번만': 696, '다음': 697, '충언': 698, '응함': 699, '퉁': 700, '명': 701, '움': 702, '실수': 703, '눌로': 704, '먾': 705, '새롭다': 706, '을해': 707, '아들': 708, '짜증나다': 709, '부정': 710, '확': 711, '살인': 712, '게뭐': 713, '본': 714, '용한': 715, '중단': 716, '귀': 717, '찬': 718, '질질': 719, '매달': 720, '상황': 721, '여간': 722, '성가시다': 723, '하라': 724, '더욱더': 725, '발전': 726, '초기': 727, '잘못': 728, '세번': 729, '만에': 730, '하지만': 731, '예쁘다': 732, '려고': 733, '마스크': 734, '착용': 735, '에이': 736, '에스': 737, '으로나': 738, '권': 739, '온라인': 740, '많아지다': 741, '짱': 742, '황상': 743, '타다': 744, '그리고': 745, '스마트': 746, '시국': 747, '고생': 748, '아파트': 749, '에보니': 750, '아래쪽': 751, '안보': 752, '여서': 753, '른것': 754, '와의': 755, '원활하다': 756, '대신': 757, '촣': 758, '겠다': 759, '제한': 760, '어요': 761, '설사': 762, '맨트': 763, '알아듣다': 764, '번시': 765, '바쁘다': 766, '시간대': 767, '역량': 768, '강화': 769, '전문': 770, '불구': 771, '움직이다': 772, '무엇': 773, '혼란': 774, '반드시': 775, '유플러스': 776, '좋아지다': 777, '저렴하다': 778, '이벤트': 779, '요망': 780, '글쎄요': 781, '제유': 782, '불미': 783, '하나': 784, '예전': 785, '묻다': 786, '분만': 787, '잃어버리다': 788, '접수': 789, '미안하다': 790, '염려': 791, '두고두고': 792, '싣다': 793, '가요': 794, '약간': 795, '치다': 796, '분동': 797, '헤멧': 798, '혼내다': 799, '조정': 800, '사용자': 801, '동의': 802, '얻다': 803, '거': 804, '지랄': 805, '이야': 806, '다이슨': 807, '천천히': 808, '이나라': 809, '기업': 810, '긍지': 811, '으로만': 812, '속도': 813, '팬': 814, '현': 815, '무시': 816, '재산세': 817, '캐쉬': 818, '없애다': 819, '햇음': 820, '또는': 821, '바': 822, '끼다': 823, '어르신': 824, '동일하다': 825, '애로': 826, '노력': 827, '몇번': 828, '재차': 829, '물어': 830, '힌': 831, '강하다': 832, '짫았으': 833, '기업인': 834, '만큼': 835, '우수하다': 836, '의하다': 837, '한화': 838, '손해': 839, '보럼': 840, '심': 841, '프로모션': 842, '주기': 843, '바람': 844, '깔다': 845, '실상': 846, '드': 847, '불쾌감': 848, '잊다': 849, '금세': 850, '잊혀지다': 851, '따다': 852, '테레콤': 853, '노인': 854, '돕기': 855, '좋아하다': 856, '부서': 857, '몇': 858, '건': 859, '뿌듯하다': 860, '자신감': 861, '넘치다': 862, '괜시리': 863, '그만큼': 864, '일이': 865, '불친절': 866, '정신없이': 867, '질': 868, '그만하다': 869, '직관': 870, '통화량': 871, '프로': 872, '줄어들다': 873, '제도': 874, '덕분': 875, '인하다': 876, '불평': 877, '생기': 878, '도중': 879, '자르다': 880, '경향': 881, '디지다': 882, '컬': 883, '매': 884, '유': 885, '로봇': 886, '딱딱하다': 887, '안좋다': 888, '맘': 889, '듭니': 890, '감염': 891, '벽': 892, '이랑': 893, '이르다': 894, '박': 895, '동': 896, '축소': 897, '추석': 898, '연휴': 899, '닥치다': 900, '절': 901, '상단': 902, '스크립트': 903, '읽다': 904, '부자연': 905, '신': 906, '헤매다': 907, '보임': 908, '숙지': 909, '자본': 910, '인과': 911, '답안': 912, '아무렇다': 913, '본기': 914, '배': 915, '요구': 916, '폰': 917, '으로의': 918, '차례': 919, '가능': 920, '가족': 921, '엊': 922, 'ㅅ': 923, '었음': 924, '그래도': 925, '각각': 926, 'ㅎㅎㅎ': 927, '어플': 928, '기르다': 929, '소요': 930, '면대': 931, '염결': 932, '낯': 933, '추다': 934, '전략': 935, '필요시': 936, '적절하다': 937, '항': 938, '친': 939, '돌아가다': 940, '출생': 941, '년도': 942, '일별': 943, '한다는': 944, '그래서': 945, '요일': 946, '인터페이스': 947, '이어지다': 948, '상대': 949, '기해': 950, '미만': 951, '크게': 952, '마다': 953, '거의': 954, '비슷': 955, '기간': 956, '묭': 957, '한동안': 958, '기대': 959, '꼼수': 960, '부리다': 961, '요전': 962, '눌': 963, '내내': 964, '거슬리다': 965, '절실': 966, '참고': 967, '똑바로': 968, '설치': 969, '기사': 970, '맴': 971, '원함': 972, '상기': 973, '문항': 974, '의문': 975, '충분하다': 976, '말소리': 977, '활용': 978, '이면': 979, '이라고': 980, '지속': 981, '여부': 982, '영결': 983, '이듬': 984, '어느': 985, '굿': 986, '공휴일': 987, '비상': 988, '배치': 989, '고전': 990, '클래식': 991, '닷': 992, '김': 993, '까지가': 994, '길댜': 995, '늘리다': 996, '요즘': 997, '매번': 998, '지나가다': 999, '한두': 1000, '되게': 1001, '기계': 1002, '만들기': 1003, '금고': 1004, '푸다': 1005, '업': 1006, '골절': 1007, '만원': 1008, '기침': 1009, '집중': 1010, 'ㅈ': 1011, '진정': 1012, '몸': 1013, '건강하다': 1014, '부드럽다': 1015, '연체': 1016, '미납': 1017, '무한': 1018, '중심': 1019, '화가': 1020, '남': 1021, '대단하다': 1022, '기초': 1023, '발성': 1024, '볍': 1025, '표준어': 1026, '훈련': 1027, '롬': 1028, '복사': 1029, '붙여넣기': 1030, '시발': 1031, '놈': 1032, '하나카드': 1033, '못지않다': 1034, '연령': 1035, '감안': 1036, '받아들이다': 1037, '엇습': 1038, '나르다': 1039, '요청': 1040, '담다': 1041, 'ㅠ': 1042, '바로바로': 1043, '손쉽다': 1044, '휠씬': 1045, '투성이': 1046, '바르다': 1047, '결재': 1048, '까지의': 1049, '모든': 1050, '가능성': 1051, '열다': 1052, '하드': 1053, '칭찬': 1054, '불안하다': 1055, '정보': 1056, '기쁘다': 1057, '안심': 1058, '돌아오다': 1059, '가알': 1060, '시대': 1061, '든': 1062, '자의': 1063, '통회': 1064, '언제나': 1065, 'ㅡㅡ': 1066, '이해도': 1067, '답장': 1068, '지정': 1069, '향후': 1070, '딥': 1071, '랑': 1072, '국민': 1073, '비교': 1074, '미흡': 1075, '린다': 1076, '밤': 1077, '장기': 1078, '단기': 1079, '보완': 1080, '전의': 1081, '라스': 1082, '위': 1083, '계심': 1084, '냥': 1085, '싸다': 1086, '저리': 1087, '안내받다': 1088, '프리미엄': 1089, '유지': 1090, '한마디': 1091, '다시다': 1092, '렌트': 1093, '기도': 1094, '저기': 1095, '어디': 1096, '줄이다': 1097, '믜': 1098, '왓으': 1099, '헝상': 1100, 'ㅎㅐ': 1101, '개인정보': 1102, '간편하다': 1103}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxXqVVZUF6hZ",
        "outputId": "cfce2bf3-a19a-42aa-b5da-258497dd1424"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 1103\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 616\n",
            "단어 집합에서 희귀 단어의 비율: 55.84768812330009\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 10.947218766660743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tu5cAYO-d5E"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(train_data['코드'])\n",
        "y_test = to_categorical(test_data['코드'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGwmGwnhx9a5",
        "outputId": "24ff5c83-4679-4ad7-e7b4-03de374aa913"
      },
      "source": [
        "len(y_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub9unDYxO8Jx",
        "outputId": "21fbfaa6-5c32-42d6-9ae0-376639c5badc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zqcZi8mG3SE"
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYabMnaXG8o4",
        "outputId": "eeb5ef88-e3b5-4ca1-ea6d-85b309cecaa4"
      },
      "source": [
        "# 빈 샘플들을 제거\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n",
            "750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "uMQ3jeOM-jy5",
        "outputId": "9360c652-2eb6-4c74-b612-fbc99735ae89"
      },
      "source": [
        "# 패딩 - 길이 맞추기\n",
        "\n",
        "print('발화의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('발화의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "발화의 최대 길이 : 73\n",
            "발화의 평균 길이 : 7.502666666666666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYyklEQVR4nO3de5QedZ3n8fdHVHQQBYbIQREDyuBlRiJG1CM6KKMiuCqzymXHOxp1ccAdLxtGVxnPesR1vI3uoEEQxkVERZQVjsowIDoqkEAGwm3kEtYwkURBbipK+O4fVf340HSSStLPpbvfr3PqdNWvnqfq03k6/e36VdWvUlVIkgTwoFEHkCSND4uCJKnHoiBJ6rEoSJJ6LAqSpJ4HjzrAlthxxx1r/vz5o44hSTPKsmXLflFV86ZaN6OLwvz581m6dOmoY0jSjJLkpvWts/tIktRjUZAk9VgUJEk9FgVJUo9FQZLUY1GQJPVYFCRJPRYFSVKPRUGS1DOj72getvmLz56yfeVxBw05iSQNxsCOFJKclGRNkhV9bacnWd5OK5Msb9vnJ/lN37rPDSqXJGn9BnmkcDLwWeCfJhqq6tCJ+SQfB27ve/31VbVggHkkSRsxsKJQVRcmmT/VuiQBDgFeOKj9S5I23ahOND8PuKWqftrXtluSy5J8P8nz1vfGJIuSLE2ydO3atYNPKklzyKiKwuHAaX3Lq4Fdq+rpwN8AX07yyKneWFVLqmphVS2cN2/K4cAlSZtp6EUhyYOBvwROn2irqnuq6pft/DLgeuBPhp1Nkua6URwp/AVwTVWtmmhIMi/JVu387sAewA0jyCZJc9ogL0k9DfgxsGeSVUmOaFcdxv27jgCeD1zeXqL6deBtVXXroLJJkqY2yKuPDl9P+xumaDsDOGNQWSRJ3TjMhSSpx6IgSeqxKEiSeiwKkqQei4IkqceiIEnqsShIknosCpKkHouCJKnHoiBJ6rEoSJJ6LAqSpB6LgiSpx6IgSeqxKEiSeiwKkqQei4IkqceiIEnqsShIknosCpKknoEVhSQnJVmTZEVf27FJbk6yvJ0O7Ft3TJLrklyb5CWDyiVJWr9BHimcDBwwRfsnq2pBO50DkOQpwGHAU9v3/GOSrQaYTZI0hYEVhaq6ELi148tfAXylqu6pqhuB64B9BpVNkjS1UZxTeEeSy9vupe3btscCP+t7zaq27QGSLEqyNMnStWvXDjqrJM0pwy4KxwNPABYAq4GPb+oGqmpJVS2sqoXz5s2b7nySNKcNtShU1S1Vta6q7gNO4A9dRDcDj+t76S5tmyRpiIZaFJLs3Ld4MDBxZdJZwGFJtk6yG7AHcPEws0mS4MGD2nCS04D9gB2TrAI+COyXZAFQwErgrQBVdWWSrwJXAfcCR1bVukFlkyRNbWBFoaoOn6L5xA28/sPAhweVR5K0cd7RLEnqsShIknosCpKkHouCJKnHoiBJ6rEoSJJ6LAqSpB6LgiSpx6IgSeqxKEiSeiwKkqQei4IkqceiIEnq2WhRSPLqJNu28+9P8o0kew8+miRp2LocKfyPqrozyb7AX9AMf338YGNJkkahS1GYeNjNQcCSqjobeOjgIkmSRqVLUbg5yeeBQ4Fzkmzd8X2SpBmmyy/3Q4DvAi+pql8BOwDvGWgqSdJIbLQoVNWvgTXAvm3TvcBPBxlKkjQaG31Gc5IPAguBPYEvAg8B/g/w3MFGG535i88edQRJGoku3UcHAy8H7gaoqv8Att3Ym5KclGRNkhV9bR9Lck2Sy5OcmWS7tn1+kt8kWd5On9u8b0eStCW6FIXfVVUBBZBkm47bPhk4YFLbucCfVtXTgH8Hjulbd31VLWint3XchyRpGnUpCl9trz7aLslbgH8GTtjYm6rqQuDWSW3fq6p728WfALtsYl5J0gBt9JxCVf19khcBd9CcV/hAVZ07Dft+E3B63/JuSS5r9/P+qvrBVG9KsghYBLDrrrtOQwxJ0oSNFgWAtghMRyEAIMn7aK5iOrVtWg3sWlW/TPIM4JtJnlpVd0yRZQmwBGDhwoU1XZkkSRsoCknupD2PMHkVUFX1yM3ZYZI3AC8D9m/PVVBV9wD3tPPLklwP/AmwdHP2IUnaPOstClW10SuMNlWSA4D3An/e3v8w0T4PuLWq1iXZHdgDuGG69y9J2rBO3UftqKj70hw5/LCqLuvwntOA/YAdk6wCPkhztdHWwLlJAH7SXmn0fOBDSX4P3Ae8rapunXLDkqSB6XLz2geAVwPfaJtOTvK1qvqfG3pfVR0+RfOJ63ntGcAZG8siSRqsLkcKfwXsVVW/BUhyHLAc2GBRkCTNPF3uU/gP4GF9y1sDNw8mjiRplLocKdwOXJnkXJpzCi8CLk7yDwBVddQA80mShqhLUTiznSZcMJgokqRR63JH8ynDCCJJGr2NnlNI8rIklyW5NckdSe5M8oA7jSVJM1+X7qNPAX8JXDFxB7IkaXbqcvXRz4AVFgRJmv26HCm8FzgnyfdpxycCqKpPDCyVJGkkuhSFDwN30dyr8NDBxpEkjVKXovCYqvrTgSeRJI1cl3MK5yR58cCTSJJGrktReDvwnSS/8ZJUSZrduty8Nu3PVZAkjaeuz1PYnubBN72B8arqwkGFkiSNRpfnKbwZOBrYhWbI7GcDPwZeONhokqRh63JO4WjgmcBNVfUC4OnArwaaSpI0El2Kwm/7HrCzdVVdA+w52FiSpFHock5hVZLtgG/SPFv5NuCmwcaSJI1Cl6uPDm5nj01yPvAo4DsDTSVJGokuJ5qfAKyqqnuAAPOBPwJ+1+G9JwEvA9ZM3BWdZAfg9HY7K4FDquq2JAE+DRwI/Bp4Q1Vduunf0viYv/jsKdtXHnfQkJNIUjddzimcAaxL8kRgCfA44Msdt38ycMCktsXAeVW1B3BeuwzwUprLXvcAFgHHd9yHJGmadCkK91XVvcDBwGeq6j3Azl023t7LcOuk5lcAE09zOwV4ZV/7P1XjJ8B2STrtR5I0PboUhd8nORx4PfDttu0hW7DPnapqdTv/c2Cndv6xNM9umLCqbbufJIuSLE2ydO3atVsQQ5I0WZei8EbgOcCHq+rGJLsBX5qOnbcP7tmkh/dU1ZKqWlhVC+fNmzcdMSRJrS5XH10FHNW3fCPw0S3Y5y1Jdq6q1W330Jq2/Waa8xUTdmnbJElD0uVIYbqdRdMVRfv1W33tr0vj2cDtfd1MkqQh6DQg3uZKchqwH7BjklXAB4HjgK8mOYLmJrhD2pefQ3M56nU0l6S+cZDZJEkPtN6ikORLVfXaJEdX1ac3Z+NVdfh6Vu0/xWsLOHJz9iNJmh4b6j56RpLHAG9Ksn2SHfqnYQWUJA3PhrqPPkdzc9nuwDKau5knVNsuSZpF1nukUFX/UFVPBk6qqt2rare+yYIgSbNQl0tS355kL+B5bdOFVXX5YGNJkkZho5ekJjkKOBV4dDudmuSvBx1MkjR8XS5JfTPwrKq6GyDJR2kex/mZQQaTJA1fl5vXAqzrW17H/U86S5JmiS5HCl8ELkpyZrv8SuDEwUWSJI1KlxPNn0hyAbBv2/TGqrpsoKkkSSPRaZiL9gloM/opaJKkjRvFgHiSpDFlUZAk9WywKCTZKsn5wwojSRqtDRaFqloH3JfkUUPKI0kaoS4nmu8CrkhyLnD3RGNVHbX+t0iSZqIuReEb7SRJmuW63KdwSpKHA7tW1bVDyCRJGpEuA+L9J2A58J12eUGSswYdTJI0fF0uST0W2Af4FUBVLccH7EjSrNSlKPy+qm6f1HbfIMJIkkary4nmK5P8F2CrJHsARwE/2twdJtkTOL2vaXfgA8B2wFuAtW3731bVOZu7H0nSputypPDXwFOBe4DTgDuAd27uDqvq2qpaUFULgGcAvwYmRmD95MQ6C4IkDV+Xq49+DbyvfbhOVdWd07j//YHrq+qmxEc0SNKobbQoJHkmcBKwbbt8O/Cmqlo2Dfs/jOboY8I7krwOWAq8q6pumyLPImARwK677rpFO5+/+Owter8kzTZduo9OBP5rVc2vqvnAkTQP3tkiSR4KvBz4Wtt0PPAEYAGwGvj4VO+rqiVVtbCqFs6bN29LY0iS+nQpCuuq6gcTC1X1Q+Deadj3S4FLq+qWdru3VNW6qroPOIHmMlhJ0hCtt/soyd7t7PeTfJ6mm6eAQ4ELpmHfh9PXdZRk56pa3S4eDKyYhn1IkjbBhs4pTO6++WDffG3JTpNsA7wIeGtf8/9KsqDd9spJ6yRJQ7DeolBVLxjUTqvqbuCPJ7W9dlD7kyR10+Xqo+2A1wHz+1/v0NmSNPt0uaP5HOAnwBU4vIUkzWpdisLDqupvBp5EkjRyXS5J/VKStyTZOckOE9PAk0mShq7LkcLvgI8B7+MPVx0VDp8tSbNOl6LwLuCJVfWLQYeRJI1Wl+6j62hGMpUkzXJdjhTuBpYnOZ9m+GzAS1IlaTbqUhS+2U6SpFmuy/MUThlGkJnMIbglzRZd7mi+kSnGOqoqrz6SpFmmS/fRwr75hwGvBrxPQZJmoY1efVRVv+ybbq6qTwEHDSGbJGnIunQf7d23+CCaI4cuRxiSpBmmyy/3/ucq3EvzrINDBpJGkjRSXa4+GthzFSRJ46VL99HWwH/mgc9T+NDgYkmSRqFL99G3gNuBZfTd0SxJmn26FIVdquqAgSeRJI1clwHxfpTkzwaeRJI0cl2OFPYF3tDe2XwPEKCq6mlbsuMkK4E7gXXAvVW1sH14z+k05y9WAodU1W1bsh9JUnddisJLB7j/F0x6TsNi4LyqOi7J4nb5vw9w/5KkPl0uSb1pGEFarwD2a+dPAS7AoiBJQ9PlnMKgFPC9JMuSLGrbdqqq1e38z4GdJr8pyaIkS5MsXbt27bCyStKcMMrhKvatqpuTPBo4N8k1/SurqpJMNTrrEmAJwMKFCx+wXpK0+UZ2pFBVN7df1wBnAvsAtyTZGaD9umZU+SRpLhpJUUiyTZJtJ+aBFwMrgLOA17cvez3NjXOSpCEZVffRTsCZSSYyfLmqvpPkEuCrSY4AbsKB9yRpqEZSFKrqBmCvKdp/Cew//ESSJBjt1UeSpDFjUZAk9VgUJEk9FgVJUo9FQZLUY1GQJPVYFCRJPaMc+2jOmr/47CnbVx530JCTSNL9eaQgSerxSGGMeAQhadQ8UpAk9VgUJEk9FgVJUo9FQZLUY1GQJPVYFCRJPRYFSVKPRUGS1GNRkCT1WBQkST1DLwpJHpfk/CRXJbkyydFt+7FJbk6yvJ0OHHY2SZrrRjH20b3Au6rq0iTbAsuSnNuu+2RV/f0IMkmSGEFRqKrVwOp2/s4kVwOPHXaO2cyB9SRtrpGeU0gyH3g6cFHb9I4klyc5Kcn263nPoiRLkyxdu3btkJJK0twwsqKQ5BHAGcA7q+oO4HjgCcACmiOJj0/1vqpaUlULq2rhvHnzhpZXkuaCkRSFJA+hKQinVtU3AKrqlqpaV1X3AScA+4wimyTNZaO4+ijAicDVVfWJvvad+152MLBi2Nkkaa4bxdVHzwVeC1yRZHnb9rfA4UkWAAWsBN46gmySNKeN4uqjHwKZYtU5w84iSbo/72iWJPVYFCRJPRYFSVLPKE40axN5h7KkYbEozGDrKxaStLnsPpIk9VgUJEk9FgVJUo/nFOaQDZ2D8KS1JPBIQZLUxyMFbRYvk5VmJ4uCAH/JS2rYfSRJ6rEoSJJ6LAqSpB6LgiSpxxPNUh/v5dBc55GCJKnHIwVNq0Ff2uqls9JgWRQ0Ug7/LY2XsSsKSQ4APg1sBXyhqo4bcaQ5bbp+aY/bL/9xyyONi7E6p5BkK+B/Ay8FngIcnuQpo00lSXPHuB0p7ANcV1U3ACT5CvAK4KqRptKMNYwjgk3dx6jOf8zF8zGb+j2P47/RsDOlqgay4c2R5FXAAVX15nb5tcCzquodfa9ZBCxqF/cEru24+R2BX0xj3EGaKVnNOb1mSk6YOVnNObXHV9W8qVaM25HCRlXVEmDJpr4vydKqWjiASNNupmQ15/SaKTlh5mQ156Ybq3MKwM3A4/qWd2nbJElDMG5F4RJgjyS7JXkocBhw1ogzSdKcMVbdR1V1b5J3AN+luST1pKq6cpo2v8ldTiM0U7Kac3rNlJwwc7KacxON1YlmSdJojVv3kSRphCwKkqSeOVEUkhyQ5Nok1yVZPOo8E5KclGRNkhV9bTskOTfJT9uv248yY5vpcUnOT3JVkiuTHD3GWR+W5OIk/9Zm/bu2fbckF7U/A6e3FzKMXJKtklyW5Nvt8tjlTLIyyRVJlidZ2raN42e/XZKvJ7kmydVJnjOmOfds/y0npjuSvHNcss76ojDmQ2ecDBwwqW0xcF5V7QGc1y6P2r3Au6rqKcCzgSPbf8NxzHoP8MKq2gtYAByQ5NnAR4FPVtUTgduAI0aYsd/RwNV9y+Oa8wVVtaDvWvpx/Ow/DXynqp4E7EXz7zp2Oavq2vbfcgHwDODXwJmMS9aqmtUT8Bzgu33LxwDHjDpXX575wIq+5WuBndv5nYFrR51xiszfAl407lmBPwIuBZ5Fc7fog6f6mRhhvl1o/vO/EPg2kDHNuRLYcVLbWH32wKOAG2kvnhnXnFPkfjHwr+OUddYfKQCPBX7Wt7yqbRtXO1XV6nb+58BOowwzWZL5wNOBixjTrG2XzHJgDXAucD3wq6q6t33JuPwMfAp4L3Bfu/zHjGfOAr6XZFk7zAyM32e/G7AW+GLbHfeFJNswfjknOww4rZ0fi6xzoSjMWNX8yTA21wwneQRwBvDOqrqjf904Za2qddUcmu9CM8jik0Yc6QGSvAxYU1XLRp2lg32ram+aLtgjkzy/f+WYfPYPBvYGjq+qpwN3M6n7ZUxy9rTni14OfG3yulFmnQtFYaYNnXFLkp0B2q9rRpwHgCQPoSkIp1bVN9rmscw6oap+BZxP0w2zXZKJmzXH4WfgucDLk6wEvkLThfRpxi8nVXVz+3UNTd/3PozfZ78KWFVVF7XLX6cpEuOWs99LgUur6pZ2eSyyzoWiMNOGzjgLeH07/3qa/vuRShLgRODqqvpE36pxzDovyXbt/MNpzn1cTVMcXtW+bORZq+qYqtqlqubT/Ez+S1X9FWOWM8k2SbadmKfpA1/BmH32VfVz4GdJ9myb9qcZcn+sck5yOH/oOoJxyTrqEy1DOplzIPDvNH3L7xt1nr5cpwGrgd/T/KVzBE2/8nnAT4F/BnYYg5z70hzKXg4sb6cDxzTr04DL2qwrgA+07bsDFwPX0Ryubz3qrH2Z9wO+PY452zz/1k5XTvz/GdPPfgGwtP3svwlsP44526zbAL8EHtXXNhZZHeZCktQzF7qPJEkdWRQkST0WBUlSj0VBktRjUZAk9VgUNGMkuWsA21yQ5MC+5WOTvHsLtvfqdoTO86cn4WbnWJlkx1Fm0MxkUdBct4DmnovpcgTwlqp6wTRuUxoai4JmpCTvSXJJksv7npkwv/0r/YT2WQrfa+9qJskz29cuT/KxJCvaO9w/BBzath/abv4pSS5IckOSo9az/8PbZwysSPLRtu0DNDf6nZjkY5Nev3OSC9v9rEjyvLb9+CRL0/fsh7Z9ZZKPTDzDIMneSb6b5Pokb2tfs1+7zbPTPC/kc0ke8H86yWvSPGNieZLPtwMGbpXk5DbLFUn+2xZ+JJotRn1nn5NT1wm4q/36YpoHnYfmD5tvA8+nGYb8XmBB+7qvAq9p51cAz2nnj6Mdrhx4A/DZvn0cC/wI2BrYkeau04dMyvEY4P8B82gGYvsX4JXtuguAhVNkfxd/uBt4K2Dbdn6HvrYLgKe1yyuBt7fzn6S5S3fbdp+3tO37Ab+luet4K5oRYV/V9/4dgScD/3fiewD+EXgdzTj+5/bl227Un6/TeEweKWgmenE7XUbzvIQnAXu0626squXt/DJgfjsW0rZV9eO2/csb2f7ZVXVPVf2CZlCyyUMYPxO4oKrWVjPM9ak0RWlDLgHemORY4M+q6s62/ZAkl7bfy1NpHgQ1YWKMriuAi6rqzqpaC9wzMb4TcHFV3VBV62iGTdl30n73pykAl7TDie9PU0RuAHZP8pkkBwB3INH8lSPNNAE+UlWfv19j86yHe/qa1gEP34ztT97GFv8/qaoL2yGnDwJOTvIJ4AfAu4FnVtVtSU4GHjZFjvsmZbqvL9PkcWomLwc4paqOmZwpyV7AS4C3AYcAb9rU70uzj0cKmom+C7ypfb4DSR6b5NHre3E1Q2jfmeRZbdNhfavvpOmW2RQXA3+eZMc0j3s9HPj+ht6Q5PE03T4nAF+gGdb5kTTj/t+eZCeaoZQ31T7tCMAPAg4Ffjhp/XnAqyb+fdI8B/jx7ZVJD6qqM4D3t3kkjxQ081TV95I8GfhxM6o3dwGvofmrfn2OAE5Ich/NL/Db2/bzgcVt18pHOu5/dZLF7XtD0920sWGO9wPek+T3bd7XVdWNSS4DrqF5OuC/dtn/JJcAnwWe2OY5c1LWq5K8n+bJaQ+iGZH3SOA3NE8pm/jD8AFHEpqbHCVVc0KSR1TVXe38Yppn4R494lhbJMl+wLur6mWjzqLZwyMFzRUHJTmG5mf+JpqrjiRN4pGCJKnHE82SpB6LgiSpx6IgSeqxKEiSeiwKkqSe/w+MBg5V9c4UUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FskN6iPC-4Nd",
        "outputId": "750b52a6-2403-43a1-8286-461dd88a6eb6"
      },
      "source": [
        "# 샘플 길이에 따른 비율 확인\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
        "\n",
        "max_len = 30\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 30 이하인 샘플의 비율: 98.13333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuaIaWan-8pb",
        "outputId": "860e0e08-db76-44a7-be42-82f1e4cb6d4a"
      },
      "source": [
        "max_len = 30\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 30 이하인 샘플의 비율: 98.13333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQy2t9Yi_wQq"
      },
      "source": [
        "# 발화 길이 30으로 맞추기\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVtogYW_QXPg",
        "outputId": "cad5916e-b373-4451-e1ac-783823c373be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "5UM6qeiPRyQW",
        "outputId": "02cc5756-fa40-44bf-a6aa-a9da657be3b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    7,  208,  102],\n",
              "       [   0,    0,    0, ...,    1,   15,   19],\n",
              "       [   0,    0,    0, ...,   10,    4,   33],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    1,   15,   19],\n",
              "       [   0,    0,    0, ...,  239, 1103,    8],\n",
              "       [   0,    0,    0, ...,    2,    1,    3]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e43wdcet_1LG"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcgUPbcQ_359"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(1104, 128)) # 문자 학습시 임베딩 사용, (단어 종류 수, 출력 차원)\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(44, activation='softmax')) # 클래스 수, 활성화 함수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKPivZd4BuuE"
      },
      "source": [
        "# 검증 데이터 손실 4회 증가하면 과적합 징후로 학습 조기 종료,ModelCheckpoint를 사용하여 검증 데이터의 정확도(val_acc)가 이전보다 좋아질 경우에만 모델을 저장\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv-Z_Iw_CCTE"
      },
      "source": [
        "#다중 클래스 분류(Multi-Class Classification) 문제이므로 손실 함수로는 categorical_crossentropy를 사용\n",
        "# categorical_crossentropy는 모델의 예측값과 실제값에 대해서 두 확률 분포 사이의 거리를 최소화하도록 훈련\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGejTlUEGjz",
        "outputId": "e336e0c5-9350-451d-ab4b-970392de9331"
      },
      "source": [
        "h = model.fit(X_train, y_train, batch_size=60, epochs=30, callbacks=[es, mc], validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 3.3871 - acc: 0.3015\n",
            "Epoch 00001: val_acc improved from -inf to 0.29200, saving model to best_model.h5\n",
            "13/13 [==============================] - 15s 184ms/step - loss: 3.2490 - acc: 0.3093 - val_loss: 2.5498 - val_acc: 0.2920\n",
            "Epoch 2/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2225 - acc: 0.2667\n",
            "Epoch 00002: val_acc did not improve from 0.29200\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 2.2225 - acc: 0.2667 - val_loss: 2.3738 - val_acc: 0.2920\n",
            "Epoch 3/30\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 2.0767 - acc: 0.2833\n",
            "Epoch 00003: val_acc did not improve from 0.29200\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 2.0852 - acc: 0.2827 - val_loss: 2.2660 - val_acc: 0.2920\n",
            "Epoch 4/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9854 - acc: 0.3027\n",
            "Epoch 00004: val_acc improved from 0.29200 to 0.32400, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 1.9854 - acc: 0.3027 - val_loss: 2.1453 - val_acc: 0.3240\n",
            "Epoch 5/30\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.8347 - acc: 0.3606\n",
            "Epoch 00005: val_acc improved from 0.32400 to 0.38400, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 1.8306 - acc: 0.3747 - val_loss: 1.9896 - val_acc: 0.3840\n",
            "Epoch 6/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.6528 - acc: 0.4722\n",
            "Epoch 00006: val_acc improved from 0.38400 to 0.47200, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 1.6526 - acc: 0.4733 - val_loss: 1.8500 - val_acc: 0.4720\n",
            "Epoch 7/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.5365 - acc: 0.5208\n",
            "Epoch 00007: val_acc improved from 0.47200 to 0.50800, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 1.5303 - acc: 0.5187 - val_loss: 1.7745 - val_acc: 0.5080\n",
            "Epoch 8/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.4356 - acc: 0.5861\n",
            "Epoch 00008: val_acc improved from 0.50800 to 0.54400, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 1.4374 - acc: 0.5880 - val_loss: 1.6869 - val_acc: 0.5440\n",
            "Epoch 9/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3226 - acc: 0.6387\n",
            "Epoch 00009: val_acc improved from 0.54400 to 0.60400, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 1.3226 - acc: 0.6387 - val_loss: 1.5893 - val_acc: 0.6040\n",
            "Epoch 10/30\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1663 - acc: 0.6909\n",
            "Epoch 00010: val_acc did not improve from 0.60400\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 1.1511 - acc: 0.6947 - val_loss: 1.4935 - val_acc: 0.6040\n",
            "Epoch 11/30\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0227 - acc: 0.7111\n",
            "Epoch 00011: val_acc improved from 0.60400 to 0.63200, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.0020 - acc: 0.7227 - val_loss: 1.4053 - val_acc: 0.6320\n",
            "Epoch 12/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8790 - acc: 0.7840\n",
            "Epoch 00012: val_acc improved from 0.63200 to 0.65200, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.8790 - acc: 0.7840 - val_loss: 1.3307 - val_acc: 0.6520\n",
            "Epoch 13/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.7711 - acc: 0.8160\n",
            "Epoch 00013: val_acc improved from 0.65200 to 0.68400, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.7711 - acc: 0.8160 - val_loss: 1.2722 - val_acc: 0.6840\n",
            "Epoch 14/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.6587 - acc: 0.8444\n",
            "Epoch 00014: val_acc improved from 0.68400 to 0.70800, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 0.6581 - acc: 0.8400 - val_loss: 1.2260 - val_acc: 0.7080\n",
            "Epoch 15/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.5950 - acc: 0.8653\n",
            "Epoch 00015: val_acc did not improve from 0.70800\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.5842 - acc: 0.8693 - val_loss: 1.2225 - val_acc: 0.7040\n",
            "Epoch 16/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5277 - acc: 0.8800\n",
            "Epoch 00016: val_acc did not improve from 0.70800\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.5277 - acc: 0.8800 - val_loss: 1.1841 - val_acc: 0.7080\n",
            "Epoch 17/30\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.4637 - acc: 0.8924\n",
            "Epoch 00017: val_acc improved from 0.70800 to 0.71600, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 0.4638 - acc: 0.8933 - val_loss: 1.1663 - val_acc: 0.7160\n",
            "Epoch 18/30\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.4401 - acc: 0.9017\n",
            "Epoch 00018: val_acc improved from 0.71600 to 0.72800, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 0.4192 - acc: 0.9107 - val_loss: 1.1527 - val_acc: 0.7280\n",
            "Epoch 19/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3588 - acc: 0.9187\n",
            "Epoch 00019: val_acc did not improve from 0.72800\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3588 - acc: 0.9187 - val_loss: 1.1276 - val_acc: 0.7080\n",
            "Epoch 20/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3142 - acc: 0.9319\n",
            "Epoch 00020: val_acc did not improve from 0.72800\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3140 - acc: 0.9320 - val_loss: 1.1346 - val_acc: 0.7120\n",
            "Epoch 21/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2970 - acc: 0.9306\n",
            "Epoch 00021: val_acc improved from 0.72800 to 0.74000, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 0.2906 - acc: 0.9333 - val_loss: 1.1329 - val_acc: 0.7400\n",
            "Epoch 22/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2590 - acc: 0.9486\n",
            "Epoch 00022: val_acc did not improve from 0.74000\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.2538 - acc: 0.9507 - val_loss: 1.1196 - val_acc: 0.6960\n",
            "Epoch 23/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2380 - acc: 0.9514\n",
            "Epoch 00023: val_acc did not improve from 0.74000\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.2342 - acc: 0.9533 - val_loss: 1.1108 - val_acc: 0.7400\n",
            "Epoch 24/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2078 - acc: 0.9583\n",
            "Epoch 00024: val_acc did not improve from 0.74000\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.2082 - acc: 0.9573 - val_loss: 1.0800 - val_acc: 0.7280\n",
            "Epoch 25/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1908 - acc: 0.9667\n",
            "Epoch 00025: val_acc improved from 0.74000 to 0.74800, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 0.1908 - acc: 0.9667 - val_loss: 1.1033 - val_acc: 0.7480\n",
            "Epoch 26/30\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1733 - acc: 0.9681\n",
            "Epoch 00026: val_acc did not improve from 0.74800\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.1701 - acc: 0.9693 - val_loss: 1.0601 - val_acc: 0.7280\n",
            "Epoch 27/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1580 - acc: 0.9733\n",
            "Epoch 00027: val_acc did not improve from 0.74800\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.1580 - acc: 0.9733 - val_loss: 1.0995 - val_acc: 0.7320\n",
            "Epoch 28/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1551 - acc: 0.9707\n",
            "Epoch 00028: val_acc did not improve from 0.74800\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.1551 - acc: 0.9707 - val_loss: 1.0946 - val_acc: 0.7200\n",
            "Epoch 29/30\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.1241 - acc: 0.9778\n",
            "Epoch 00029: val_acc did not improve from 0.74800\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.1382 - acc: 0.9733 - val_loss: 1.1193 - val_acc: 0.7440\n",
            "Epoch 30/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1266 - acc: 0.9707\n",
            "Epoch 00030: val_acc improved from 0.74800 to 0.75200, saving model to best_model.h5\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.1266 - acc: 0.9707 - val_loss: 1.0906 - val_acc: 0.7520\n",
            "Epoch 00030: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht6htfL70LBU",
        "outputId": "6c93cec2-a475-4113-e303-a62baac51b87"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 8ms/step - loss: 1.0906 - acc: 0.7520\n",
            "\n",
            " 테스트 정확도: 0.7520\n"
          ]
        }
      ]
    }
  ]
}